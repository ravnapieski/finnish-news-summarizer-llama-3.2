{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41229760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65930392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:18:24_PDT_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.10.0+cu128'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "!nvcc --version\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b254b0",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2044fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3070 Ti Laptop GPU. Num GPUs = 1. Max memory: 8.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_hf = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "MAX_SEQ_LENGTH = 2048 # required for long news articles\n",
    "load_in_4bit = True\n",
    "dtype = None\n",
    "model, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name= pretrained_model_hf,\n",
    "    max_seq_length = MAX_SEQ_LENGTH, \n",
    "    dtype = torch.bfloat16,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840d21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint: 2.31 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory footprint: {model.get_memory_footprint() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a222dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6818e283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "tokenizer.clean_up_tokenization_spaces = True\n",
    "tokenizer.add_tokens([\"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_eos_token = False\n",
    "\n",
    "model.resize_token_embeddings(new_num_tokens=len(tokenizer))\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e317da8",
   "metadata": {},
   "source": [
    "### LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3726d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.4 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    r = 32, \n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\", # saves lots of vram!!!\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,\n",
    "    loftq_config = None,\n",
    "    max_seq_length = MAX_SEQ_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f75d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed dataset from ./summarization_dataset...\n",
      "Dataset ready. Total rows: 8261\n"
     ]
    }
   ],
   "source": [
    "# Define a path to store the processed dataset\n",
    "dataset_cache_path = \"./summarization_dataset\"\n",
    "\n",
    "if os.path.exists(dataset_cache_path):\n",
    "    print(f\"Loading pre-processed dataset from {dataset_cache_path}...\")\n",
    "    dataset = load_from_disk(dataset_cache_path)\n",
    "\n",
    "else:\n",
    "    print(\"Creating dataset from scratch...\")\n",
    "    \n",
    "    def create_dataset(directory):\n",
    "        data_entries = []\n",
    "        files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "        for filename in files:\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(directory, filename), on_bad_lines='skip')\n",
    "                article = \" \".join(df['regular_string'].dropna().astype(str).tolist()).strip()\n",
    "                summary = \" \".join(df['selko_string'].dropna().astype(str).tolist()).strip()\n",
    "                \n",
    "                if len(article) > 50 and len(summary) > 10:\n",
    "                    data_entries.append({\"article\": article, \"summary\": summary})\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {filename}: {e}\")\n",
    "                continue\n",
    "        return Dataset.from_list(data_entries)\n",
    "\n",
    "    # Load raw data\n",
    "    raw_dataset = create_dataset(\"./ylenews-fi-2014-2020-selko-par-sent-src/CSV\")\n",
    "\n",
    "    def format_to_gemma(examples):\n",
    "        texts = []\n",
    "        for article, summary in zip(examples['article'], examples['summary']):\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": f\"Tiivist√§ seuraava uutinen selkosuomeksi:\\n\\n{article}\\n\"},\n",
    "                {\"role\": \"model\", \"content\": summary}\n",
    "            ]\n",
    "            text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "            texts.append(text)\n",
    "        return { \"text\": texts }\n",
    "\n",
    "    dataset = raw_dataset.map(format_to_gemma, batched=True)\n",
    "    \n",
    "    print(f\"Saving dataset to {dataset_cache_path} for future runs...\")\n",
    "    dataset.save_to_disk(dataset_cache_path)\n",
    "\n",
    "print(f\"Dataset ready. Total rows: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0449ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['article', 'summary', 'text'],\n",
      "    num_rows: 8261\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a50ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE INPUT FOR TRAINING ---\n",
      "<bos><start_of_turn>user\n",
      "Tiivist√§ seuraava uutinen selkosuomeksi:\n",
      "\n",
      "Isopanda synnytti kaksoset Chengdun pandakeskuksessa maanantaina. Kaksoset olivat ensimm√§iset t√§n√§ vuonna syntyneet. Kelin-niminen isopanda synnytti maanantaina tytt√∂kaksoset Chengdun pandankasvatuskeskuksessa Kiinan lounaisosassa. Poikaset olivat maailman ensimm√§iset t√§n√§ vuonna syntyneet pandakaksoset. Poikasten kerrotaan olevan hyv√§ss√§ kunnossa. Kaksosista vanhempi painaa 118 grammaa ja nuorempi 70 grammaa. Poikaset sy√∂v√§t vain millilitran maitoa kerrallaan ruokaillessaan, kertoo hoitajia haastatellut Kiinan valtiollinen CCTV. Pandakeskuksen emopanda tuli raskaaksi keinosiemennyksest√§. Isopanda on luokiteltu eritt√§in uhanalaiseksi lajiksi. WWF:n mukaan luonnossa el√§√§ vain 1 800 isopandaa.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "Kiinassa on syntynyt vuoden ensimm√§iset pandakaksoset. Pennut syntyiv√§t maanantaina Chengdun kaupungin keskuksessa, jossa kasvatetaan pandakarhuja. Luonnossa el√§√§ alle 2 000 isopandaa, joten se on vaarassa h√§vit√§ maailmasta kokonaan.<end_of_turn>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SAMPLE INPUT FOR TRAINING ---\")\n",
    "print(dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = dataset.shuffle(seed=3407)\n",
    "dataset_small = shuffled_dataset.select(range(1000)) # remove if you want better model, training takes longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5775d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'summary', 'text'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'summary', 'text'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "import math\n",
    "\n",
    "batch_size = 4\n",
    "eval_batch_size = 4\n",
    "gradient_accumulation_steps = 16\n",
    "epochs = 1\n",
    "train_steps = math.ceil(len(dataset_small) / batch_size / gradient_accumulation_steps * epochs)\n",
    "eval_steps = math.floor(train_steps/epochs/10)\n",
    "warmup_steps = math.ceil(train_steps * 0.1)\n",
    "\n",
    "dataset_split = dataset_small.train_test_split(test_size=0.2)\n",
    "dataset_split[\"test\"] = dataset_split[\"test\"].select(range(15)) # remove for better evaluation (takes longer)\n",
    "total_steps = 62\n",
    "print(dataset_split)\n",
    "\n",
    "output_dir = \"train_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "695ca086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9adb479731c4c2696fc382009c15d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d36fe321f149eda8968f4146e57675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Padding-free auto-enabled, enabling faster training.\n"
     ]
    }
   ],
   "source": [
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset_split[\"train\"],\n",
    "    eval_dataset = dataset_split[\"test\"],\n",
    "    max_seq_length = MAX_SEQ_LENGTH,\n",
    "    dataset_num_proc = 12, # adjust if you have less/more cores in ur cpu\n",
    "    packing = False,\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = eval_batch_size,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "        warmup_steps = warmup_steps,\n",
    "        #max_steps = train_steps,\n",
    "        eval_steps = 30,\n",
    "        save_steps = 10,\n",
    "        eval_strategy = \"steps\",\n",
    "        save_strategy = \"steps\",\n",
    "        learning_rate = 0.0001, # smaller learning rate could be better\n",
    "        fp16 = False,\n",
    "        bf16 = True,\n",
    "        logging_steps = 1,\n",
    "        optim = \"paged_adamw_8bit\",\n",
    "        weight_decay = 0.005,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3047,\n",
    "        output_dir = output_dir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51f909",
   "metadata": {},
   "source": [
    "lez send it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc56da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,600 | Num Epochs = 3 | Total steps = 75\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 16 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,066,752 (0.75% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/75 03:11 < 3:49:54, 0.01 it/s, Epoch 0.08/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3070 Ti Laptop GPU. Num GPUs = 1. Max memory: 8.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.4 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128257, 3072, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "          (1): LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "          (2-27): 26 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Try new model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"content/train_checkpoints/checkpoint-120\",\n",
    "    max_seq_length = 2048,\n",
    "    dtype = torch.bfloat16,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b61b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"Suomalaistaustaisen startup-yrityksen Donut Labin uusi akkuteknologia voi muuttaa radikaalisti kilpailuasetelmia maailman akkumarkkinoilla, jos yrityksen hurjat v√§itteet uuden akun ominaisuuksista pit√§v√§t paikkaansa.\n",
    "\n",
    "Nyky√§√§n Kiina on selv√§ss√§ johtoasemassa akkuteknologian kehitt√§misess√§ ja akkujen valmistuksessa.\n",
    "\n",
    "Lappeenrannan-Lahden teknillisen yliopiston s√§hk√∂tekniikan professorin Pertti Kaurasen mukaan Donut Labin Yhdysvaltain CES-messuilla esittelem√§ uusi kiinte√§n olomuodon akkuteknologia voisi muuttaa tilannetta Euroopan ja Suomen hyv√§ksi.\n",
    "\n",
    "‚Äì T√§llainen teknologia varmasti kelpaisi eurooppalaisille autonvalmistajille. Ne saisivat sen avulla kilpailuetua etenkin kiinalaisiin s√§hk√∂autonvalmistajiin, professori Kauranen sanoo.\n",
    "\n",
    "LUT-yliopiston s√§hk√∂tekniikan professori Pertti Kauranen kuvattuna yliopiston sis√§tiloissa. \n",
    "\n",
    "Avaa kuvien katselu\n",
    "Professori Pertti Kaurasen mielest√§ akkuteollisuuden voimatasopaino voi j√§rkky√§, jos Donut Labin akkuteknologia ly√∂ l√§pi. Kuva: Kalle Sch√∂nberg / Yle\n",
    "My√∂s Kiinan hallitseva asema nykyisen akkuteknologian kriittisten raaka-aineiden, kuten litiumin, louhinnassa ja jalostamisessa voisi horjua, koska Donut Labin mukaan sen akun raaka-aineet ovat yleisesti saatavissa.\n",
    "\n",
    "‚Äì P√§√§sisimme eroon geopoliittisista riippuvuuksista, jos raaka-aineita olisi saatavissa helposti mist√§ tahansa, Kauranen sanoo.\n",
    "\n",
    "Hurjat ominaisuudet\n",
    "Donut Lab esitteli akkuteknolgiaansa tammikuun alussa Yhdysvalloissa Las Vegasin CES-messuilla. Yrityksen mukaan kyse on maailman ensimm√§isest√§ teolliseen tuotantoon valmiista kiinte√§n olomuodon akusta.\n",
    "\n",
    "Donut Labin mukaan sen akkuja asennetaan jo virolaisen Verge Motorcyclesin valmistamiin s√§hk√∂moottoripy√∂riin, joista ensimm√§iset l√§htev√§t asiakkaille l√§hikuukausien aikana.\n",
    "\n",
    "Ylen tietojen mukaan Verge-moottoripy√∂r√§n valmistaja on kuitenkin ajautunut talouskriisiin.\n",
    "\n",
    "Donut Labin mukaan heid√§n akkunsa energiatiheys on 400 Wh/kg, se latautuu t√§yteen alle viidess√§ minuutissa ja se kest√§√§ jopa 100 000 lataussykli√§.\n",
    "\n",
    "Yhti√∂n mukaan akku toimisi l√§hes t√§ydell√§ teholla viel√§ 30 asteen pakkasessa ja yli sadan asteen kuumuudessa. Lis√§ksi akut olisi edullista valmistaa ja raaka-aineet saataisiin l√§helt√§. Akut olisivat my√∂s paloturvallisia ja ekologisia.\n",
    "\n",
    "S√§hk√∂tekniikan professori Pertti Kauranen kertoo videolla, ett√§ n√§ill√§ ominaisuuksilla suomalaisakku ohittaisi kirkkaasti nykyiset litiumakut.\n",
    "\n",
    "LUT-yliopiston s√§hk√∂tekniikan professori Pertti Kaurasen mukaan suomalaisakun v√§itetyt ominaisuudet ovat huomattavasti paremmat kuin parhaimpien nykyakkujen ominaisuudet.Video: Kalle Sch√∂nberg/Yle\n",
    "Kiinasta tyrm√§ys v√§itteille\n",
    "Donut Labin kovat v√§itteet akkuteknologiastaan ovat her√§tt√§neet ep√§ilyj√§ asiantuntijapiireiss√§.\n",
    "\n",
    "Asiaa on kommentoitu my√∂s Kiinasta. Maailman suurimpiin kuuluvan kiinalaisen akkuvalmistajan Svoltin toimitusjohtaja Yang Hongxin tyrm√§si kovin sanoin Donut Labin v√§itteet kiinalaisten tiedotusv√§lineiden haastattelussa. Hongxinin mukaan kyse on huijauksesta.\n",
    "\n",
    "My√∂s Aalto-yliopiston akkukemian ja -materiaalien professori Tanja Kallio ep√§ilee v√§itteiden paikkaansapit√§vyytt√§.\n",
    "\n",
    "‚Äì Se tuntuu ihan uskomattomalta. Se rikkoisi kaikkia niit√§ fysiikan ja kemian periaatteita, joita itse tunnen, Kallio sanoo.\n",
    "\n",
    "Teknologia tuntematonta\n",
    "Donut Lab ei ole ilmoittanut, mink√§laista teknologiaa se k√§ytt√§√§ uudessa akussaan. Yhden vihjeen teknologian mahdollisesta alkuper√§st√§ antaa Donut Labin osakkuusyrityksen Nordic Nano Groupin antamat tiedot.\n",
    "\n",
    "Imatralla tehdasta k√§ynnist√§v√§ Nordic Nano Group on kertonut, ett√§ se pystyy valmistamaan akkukennoja nanomassasta, joka on kehitetty saksalaisen tutkimuksen pohjalta.\n",
    "\n",
    "Yrityksen toimitilat lumisessa maisemassa aamuh√§m√§r√§ss√§ Imatralla.\n",
    "\n",
    "Avaa kuvien katselu\n",
    "Nordic Nano Group on k√§ynnist√§m√§ss√§ tehdasta Imatralla. Kuva: Tanja Hannus / Yle\n",
    "Nordic Nano Groupin toimitusjohtaja Esa Parjanen kertoi Ylelle vuoden 2024 lokakuussa, ett√§ nanomassa voi korvata autojen ja k√§nnyk√∂iden akuissa tyypillisesti k√§ytetyn litiumin.\n",
    "\n",
    "‚Äì N√§m√§ nanoakkukennot kest√§v√§t kymmeni√§tuhansia latauskertoja ja niihin mahtuu enemm√§n energiaa. Ne ovat my√∂s paloturvallisia, eiv√§tk√§ voi r√§j√§ht√§√§, Parjanen sanoi.\n",
    "\n",
    "Yrityksen mukaan se alkaa tuottamaan samasta aineesta Imatran-tehtaassa aurinkopaneeleja ja aurinkoenegiaa ker√§√§vi√§ ohutkalvopinnoitteita jo ennen kes√§√§. Varsinainen massatuotanto alkaa syksyll√§.\n",
    "\n",
    "Parjanen mukaan tehtaassa ei tuotettaisi akkukennoja. H√§n ei kerro, miss√§ niiden tuotanto mahdollisesti alkaa.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d02d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUMMARY ---\n",
      "Suomalainen startup-yritys Donut Lab on esitt√§nyt uuden akkuteknologian. Yritys kertoi, ett√§ sen akku on kiinte√§n olomuodon akku. Kyse on maailman ensimm√§isest√§ teollisesta tuotantoon valmiasta kiinte√§n olomuodon akusta. Donut Labin akku on 400 Wh/kg, se latautuu t√§yteen alle viidess√§ minuutissa. Akku kest√§√§ jopa 100 000 lataussykli√§. Donut Labin akku toimii l√§hes t√§ydell√§ teholla 30 asteen pakkasessa ja yli sadan asteen kuumuudessa. Akku on my√∂s paloturvallinen ja ekologinen. Donut Labin akku on parempi kuin nykyiset akut. Donut Labin akku on 400 Wh/kg, nykyiset akut ovat 150 Wh/kg.\n"
     ]
    }
   ],
   "source": [
    "# same format as training\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        # MUST match the training formatting perfectly!\n",
    "        \"content\": f\"Tiivist√§ seuraava uutinen selkosuomeksi:\\n\\n{test_article}\\n\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# tokenize with the \"Generation Prompt\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # so model knows to start answering\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# tells the model that every single token is important and not to ignore anything\n",
    "attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs,\n",
    "    max_new_tokens = 512,\n",
    "    use_cache = True,\n",
    "    temperature = 0.4, \n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs[:, inputs.shape[1]:], skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"--- SUMMARY ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3d5c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3070 Ti Laptop GPU. Num GPUs = 1. Max memory: 8.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.34. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072, padding_idx=128004)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "      (1): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "      (2-27): 26 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Try old model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = 2048,\n",
    "    dtype = torch.bfloat16,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff43ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUMMARY ---\n",
      "Suomalaista startup-yritys Donut Labin uusi akkuteknologia voisi muuttaa radikaalisti kilpailuasetelmia maailman akkumarkkinoilla. Yrityksen mukaan kyse on maailman ensimm√§isest√§ teolliseen tuotantoon valmiista kiinte√§n olomuodon akusta.\n",
      "\n",
      "Donut Labin akkuteknologia on her√§tt√§nyt ep√§ilyj√§ asiantuntijapiireiss√§, mutta yrityksen mukaan sen akkuja asennetaan jo virolaisen Verge Motorcyclesin valmistamiin s√§hk√∂moottoripy√∂riin.\n",
      "\n",
      "Verge-moottoripy√∂r√§n valmistaja on kuitenkin ajautunut talouskriisiin, ja yrityksen mukaan heid√§n akkunsa energiatiheys on 400 Wh/kg, se latautuu t√§yteen alle viidess√§ minuutissa ja se kest√§√§ jopa 100 000 lataussykli√§.\n",
      "\n",
      "S√§hk√∂tekniikan professori Pertti Kauranen kertoo videolla, ett√§ n√§ill√§ ominaisuuksilla suomalaisakku ohittaisi kirkkaasti nykyiset litiumakut.\n",
      "\n",
      "Kiinasta tyrm√§ys v√§itteille on kommentoitu my√∂s. Maailman suurimpiin kuuluvan kiinalaisen akkuvalmistajan Svoltin toimitusjohtaja Yang Hongxin tyrm√§si on her√§tt√§nyt ep√§ilyj√§. Hongxinin mukaan kyse on huijauksesta.\n",
      "\n",
      "Aalto-yliopiston akkukemian ja -materiaalien professori Tanja Kallio ep√§ilee v√§itteiden paikkaansapit√§vyytt√§.\n"
     ]
    }
   ],
   "source": [
    "# same format as training\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        # MUST match the training formatting perfectly!\n",
    "        \"content\": f\"Tiivist√§ seuraava uutinen selkosuomeksi:\\n\\n{test_article}\\n\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# tokenize with the \"Generation Prompt\"\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # so model knows to start answering\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# tells the model that every single token is important and not to ignore anything\n",
    "attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs,\n",
    "    max_new_tokens = 512,\n",
    "    use_cache = True,\n",
    ")\n",
    "\n",
    "response = tokenizer.batch_decode(outputs[:, inputs.shape[1]:], skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"--- SUMMARY ---\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_local_2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
